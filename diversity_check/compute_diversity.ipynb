{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9f959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing original lexical diversity\n",
      "N-grams: 22.11, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.27, syntactic_diversity: 0.02, semantic_diversity: 0.26\n",
      "N-grams: 23.21, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.30, syntactic_diversity: 0.02, semantic_diversity: 0.28\n",
      "N-grams: 21.16, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.25, syntactic_diversity: 0.02, semantic_diversity: 0.24\n",
      "N-grams: 40.38, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.38, syntactic_diversity: 0.03, semantic_diversity: 0.28\n",
      "N-grams: 21.15, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.24, syntactic_diversity: 0.02, semantic_diversity: 0.24\n",
      "N-grams: 22.42, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.27, syntactic_diversity: 0.02, semantic_diversity: 0.25\n",
      "N-grams: 23.26, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.27, syntactic_diversity: 0.02, semantic_diversity: 0.25\n",
      "Computing adapted lexical diversity\n",
      " --- Computing temperature value 1e-13\n",
      "N-grams: 21.92, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.25, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 19.84, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.23, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 25.44, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.26, syntactic_diversity: 0.02, semantic_diversity: 0.21\n",
      "N-grams: 20.51, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.23, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 20.02, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.25, syntactic_diversity: 0.02, semantic_diversity: 0.22\n",
      "N-grams: 22.60, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.25, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      " --- Computing temperature value 0.3\n",
      "N-grams: 21.94, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.25, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 20.49, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.24, syntactic_diversity: 0.02, semantic_diversity: 0.24\n",
      "N-grams: 25.62, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.26, syntactic_diversity: 0.02, semantic_diversity: 0.22\n",
      "N-grams: 20.44, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.23, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 20.00, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.25, syntactic_diversity: 0.02, semantic_diversity: 0.22\n",
      "N-grams: 22.65, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.25, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      " --- Computing temperature value 0.6\n",
      "N-grams: 22.28, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.25, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 20.91, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.24, syntactic_diversity: 0.02, semantic_diversity: 0.24\n",
      "N-grams: 25.44, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.26, syntactic_diversity: 0.02, semantic_diversity: 0.21\n",
      "N-grams: 21.32, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.24, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 20.54, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.25, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 23.33, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.26, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      " --- Computing temperature value 0.9\n",
      "N-grams: 23.14, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.26, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 21.15, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.24, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 26.46, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.27, syntactic_diversity: 0.02, semantic_diversity: 0.22\n",
      "N-grams: 22.12, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.24, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "N-grams: 21.88, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.26, syntactic_diversity: 0.02, semantic_diversity: 0.22\n",
      "N-grams: 24.03, BERT: 0.00, ROBERTA: 0.00, lexical_diversity: 0.27, syntactic_diversity: 0.02, semantic_diversity: 0.23\n",
      "Computing original global diversity\n",
      "Computing global diversity for mode original\n",
      "Computing adapted global diversity\n",
      "Computing global diversity for mode 1e-13\n",
      "Computing global diversity for mode 0.3\n",
      "Computing global diversity for mode 0.6\n",
      "Computing global diversity for mode 0.9\n",
      "Computing local diversity for mode 0\n",
      "Computing local diversity for mode 0.3\n",
      "Computing local diversity for mode 0.6\n",
      "Computing local diversity for mode 0.9\n"
     ]
    }
   ],
   "source": [
    "# File to compute for the recipe datasets the metrics defined in diversity_metrics.py\n",
    "import pandas as pd\n",
    "from diversity_metrics import compute_lexical_diversity, compute_global_diversity, compute_local_diversity\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "def lexical_diversity(original, adapted):\n",
    "    # Description: Compute the lexical diversity of the original and adapted datasets\n",
    "    # Input: original and adapted datasets\n",
    "    # Output: DataFrame with the lexical diversity results\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    print(\"Computing original lexical diversity\")\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        results_analysis = compute_lexical_diversity(original,separated_ingredients=True, mode=\"whole_recipe\") #one token one ingredient. Here we consider each ingredient as a token in the list. This makes the diversity higher.\n",
    "    results_analysis\n",
    "    \n",
    "    #reorder to have country and separated_ingredients as columns in dataframe\n",
    "    df = pd.DataFrame(results_analysis)\n",
    "\n",
    "\n",
    "    print(\"Computing adapted lexical diversity\")\n",
    "    list_tmp = ['1e-13', '0.3', '0.6', '0.9']\n",
    "    for tmp in list_tmp:\n",
    "        print(\" --- Computing temperature value\",tmp)\n",
    "        # filter by temperature balanced_dataset\n",
    "        df_tmp = adapted[adapted['temperature'] == tmp]\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            results_analysis = compute_lexical_diversity(df_tmp,separated_ingredients=True, tmp=tmp, ai_generated=True, mode=\"whole_recipe\")\n",
    "        \n",
    "        # concat to df\n",
    "        df = pd.concat([df, pd.DataFrame(results_analysis)], ignore_index=True)\n",
    "\n",
    "    df['mode'] = df['mode'].replace('original', -1)\n",
    "    df['mode'] = df['mode'].replace('1e-13', 0)\n",
    "\n",
    "    final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "\n",
    "    final_df \n",
    "\n",
    "    final_df.to_csv(\"res/lexical_diversity_results_all.csv\", index=False)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "\n",
    "def global_diversity(original, adapted):\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    print(\"Computing original global diversity\")\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        results_analysis = compute_global_diversity(original,tmp=\"original\", ai_generated=False) #one token one word\n",
    "    results_analysis\n",
    "    \n",
    "    #reorder to have country and separated_ingredients as columns in dataframe\n",
    "    df = pd.DataFrame(results_analysis)\n",
    "\n",
    "    print(\"Computing adapted global diversity\")\n",
    "    list_tmp = ['1e-13', '0.3', '0.6', '0.9']\n",
    "    for tmp in list_tmp:\n",
    "        # filter by temperature balanced_dataset\n",
    "        df_tmp = adapted[adapted['temperature'] == tmp]\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            results_analysis = compute_global_diversity(df_tmp,tmp=tmp, ai_generated=True) \n",
    "        \n",
    "        # concat to df\n",
    "        df = pd.concat([df, pd.DataFrame(results_analysis)], ignore_index=True)\n",
    "\n",
    "    df['mode'] = df['mode'].replace('original', -1)\n",
    "    df['mode'] = df['mode'].replace('1e-13', 0)\n",
    "    df_with_ingredients = df.copy()\n",
    "    df['global'] = df['global'].astype(int)\n",
    "    df_diversity = df.pivot(index='country', columns='mode', values=['global'])\n",
    "    df_diversity = df_diversity.reset_index()\n",
    "    df_diversity.columns.name = None\n",
    "    df_diversity.to_latex(\"latex_tables/global_diversity.tex\",index=False)\n",
    "    return df_diversity, df_with_ingredients\n",
    "\n",
    "\n",
    "# Compute local diversity\n",
    "def local_diversity(df):\n",
    "    total_entropies = compute_local_diversity(df)\n",
    "    df_local_div = pd.DataFrame(total_entropies)\n",
    "    df_local_div.to_csv(\"res/local_diversity_results_all.csv\", index=False)\n",
    "\n",
    "    # remove duplicates\n",
    "    df_local_div[['country', 'mode']] = df_local_div['country_'].str.split('_', expand=True)\n",
    "    df_local_div = df_local_div.drop(columns=['country_'])\n",
    "    df_local_div = df_local_div.drop_duplicates()\n",
    "    df_local_div.head(50)\n",
    "\n",
    "    # # Pivot the DataFrame\n",
    "    df_pivoted = df_local_div.pivot_table(index='country', columns='mode', values=['entropy'])\n",
    "    # Reset the index to make 'country' a column again\n",
    "    df_pivoted.reset_index()\n",
    "\n",
    "    # Rename columns for clarity (optional)\n",
    "    df_pivoted.columns.name = None\n",
    "\n",
    "    df_pivoted.to_latex(\"latex_tables/local_diversity.tex\")\n",
    "    return df_pivoted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "balanced_adapted_dataset = pd.read_csv(\"res/balanced_adapted_recipes.csv\")\n",
    "balanced_original_dataset = pd.read_csv(\"res/balanced_original_recipes.csv\")\n",
    "balanced_adapted_dataset['temperature'] = balanced_adapted_dataset['temperature'].astype(str)\n",
    "\n",
    "df_lexical_diversity = lexical_diversity(balanced_original_dataset, balanced_adapted_dataset)\n",
    "df_global_diversity, df_ingredients = global_diversity(balanced_original_dataset, balanced_adapted_dataset)\n",
    "df_local_diversity = local_diversity(df_ingredients)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c75716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'mod', 'country', 'ingrediente_prep', 'temperature', 'src'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "balanced_adapted_dataset.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "divcon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
